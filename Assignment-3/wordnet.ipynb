{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5f03dc-fb09-4b3d-ba9b-b46487af46ce",
   "metadata": {},
   "source": [
    "# Assignment 3: Wordnet\n",
    " Abdullah Hasani - AHH190004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a29c4-9a3a-4bf4-948c-4c4a08a55003",
   "metadata": {},
   "source": [
    "### About Wordnet\n",
    "Wordnet is an English language database that is used in natural language processing and is provided through the NLTK library. Wordnet's database contains relationships between words, such as a word's synonyms, antonyms, hypernyms and hyponyms, meronyms, and holonyms. It also has methods that can be applied to synsets, such as getting the gloss (definition) of a word, getting use case examples, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9b4e3b-3e20-4ff1-be84-a6bed1126573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hasani/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All synsets for card:\n",
      "Synset('card.n.01')\n",
      "Synset('card.n.02')\n",
      "Synset('card.n.03')\n",
      "Synset('card.n.04')\n",
      "Synset('wag.n.01')\n",
      "Synset('poster.n.01')\n",
      "Synset('calling_card.n.02')\n",
      "Synset('card.n.08')\n",
      "Synset('menu.n.01')\n",
      "Synset('batting_order.n.01')\n",
      "Synset('circuit_board.n.01')\n",
      "Synset('tease.v.07')\n",
      "Synset('card.v.02')\n",
      "\n",
      "Selected: Synset('card.n.01')\n",
      "Definition: one of a set of small pieces of stiff paper marked in various ways and used for playing games or for telling fortunes\n",
      "Usage examples: ['he collected cards and traded them with the other boys']\n",
      "Lemmas: ['card']\n",
      "\n",
      "Traversing up the hierarchy:\n",
      "Synset('paper.n.01')\n",
      "Synset('material.n.01')\n",
      "Synset('substance.n.01')\n",
      "Synset('matter.n.03')\n",
      "Synset('part.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('relation.n.01')\n",
      "Synset('entity.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "\n",
      "Hypernyms: [Synset('paper.n.01')]\n",
      "\n",
      "Hyponyms: [Synset('playing_card.n.01'), Synset('punched_card.n.01'), Synset('tarot_card.n.01'), Synset('trading_card.n.01')]\n",
      "\n",
      "Meronyms: []\n",
      "\n",
      "Holonyms: []\n",
      "\n",
      "Antonyms: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hasani/.local/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py:604: UserWarning: Discarded redundant search for Synset('entity.n.01') at depth 7\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "# Select a noun\n",
    "noun = 'card'\n",
    "\n",
    "# Output all synsets\n",
    "synsets = wn.synsets(noun)\n",
    "print(f\"All synsets for {noun}:\")\n",
    "for synset in synsets:\n",
    "    print(synset)\n",
    "\n",
    "# Select a synset\n",
    "selected = synsets[0]\n",
    "print(f\"\\nSelected: {selected}\")\n",
    "\n",
    "# Synset definition\n",
    "print(f\"Definition: {selected.definition()}\")\n",
    "\n",
    "# Synset usage examples \n",
    "print(f\"Usage examples: {selected.examples()}\")\n",
    "\n",
    "# Synset lemmas\n",
    "print(f\"Lemmas: {[lemma.name() for lemma in selected.lemmas()]}\")\n",
    "\n",
    "# Traversal over WordNet heirarchy\n",
    "hypernyms = lambda s: s.hypernyms()\n",
    "hyper_list = list(selected.closure(hypernyms))\n",
    "\n",
    "# Outputting the synsets\n",
    "print(\"\\nTraversing up the hierarchy:\")\n",
    "for word in hyper_list:\n",
    "    print(word)\n",
    "    \n",
    "# Outputting the hypernyms\n",
    "print(f'\\nHypernyms: {selected.hypernyms()}')\n",
    "\n",
    "# Outputting the hyponyms\n",
    "print(f'\\nHyponyms: {selected.hyponyms()}')\n",
    "\n",
    "# Outputting the meronyms\n",
    "print(f'\\nMeronyms: {selected.part_meronyms()}')\n",
    "\n",
    "# Outputting the holonyms\n",
    "print(f'\\nHolonyms: {selected.part_holonyms()}')\n",
    "\n",
    "# Outputting the antonyms\n",
    "print(f'\\nAntonyms: {selected.lemmas()[0].antonyms()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814f13b-06c2-43fc-81fe-96c6de32ed72",
   "metadata": {},
   "source": [
    "### WordNet Organization for Nouns\n",
    "\n",
    "WordNet is organizes nouns into \"synsets\", or sets of synonyms, which describes a word and the words that are closely related in definition to it. It then also has antonym relationships with other words to represent the opposite of a word, if it exists. It also has part-whole relationships, known as meronyms and holonyms, where a meronym is a part of of another thing and a holonym is the thing a word is a part of. It also has hypernyms and hyponyms, where a hypernym is a higher version of the word and a hyponym is a lower version of the word. These organized relationships exist to allow for ease of use and access when being used in the context of natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f882b1-5bca-4e42-939a-0915f307d6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All synsets for denied:\n",
      "Synset('deny.v.01')\n",
      "Synset('deny.v.02')\n",
      "Synset('deny.v.03')\n",
      "Synset('deny.v.04')\n",
      "Synset('deny.v.05')\n",
      "Synset('traverse.v.03')\n",
      "Synset('deny.v.07')\n",
      "\n",
      "Selected: Synset('deny.v.01')\n",
      "Definition: declare untrue; contradict\n",
      "Usage examples: ['He denied the allegations', 'She denied that she had taken money']\n",
      "Lemmas: ['deny']\n",
      "\n",
      "Traversing up the hierarchy:\n",
      "Synset('contradict.v.02')\n",
      "Synset('disagree.v.01')\n"
     ]
    }
   ],
   "source": [
    "# Select a verb\n",
    "verb = 'denied'\n",
    "\n",
    "# Output all synsets\n",
    "synsets = wn.synsets(verb, pos=wn.VERB)\n",
    "print(f\"All synsets for {verb}:\")\n",
    "for synset in synsets:\n",
    "    print(synset)\n",
    "\n",
    "# Select a synset\n",
    "selected = synsets[0]\n",
    "print(f\"\\nSelected: {selected}\")\n",
    "\n",
    "# Synset definition\n",
    "print(f\"Definition: {selected.definition()}\")\n",
    "\n",
    "# Synset usage examples \n",
    "print(f\"Usage examples: {selected.examples()}\")\n",
    "\n",
    "# Synset lemmas\n",
    "print(f\"Lemmas: {[lemma.name() for lemma in selected.lemmas()]}\")\n",
    "\n",
    "# Traversal over WordNet heirarchy\n",
    "hypernyms = lambda s: s.hypernyms()\n",
    "hyper_list = list(selected.closure(hypernyms))\n",
    "\n",
    "# Outputting the synsets\n",
    "print(\"\\nTraversing up the hierarchy:\")\n",
    "for word in hyper_list:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ade57b-6251-4e47-99cc-536895065001",
   "metadata": {},
   "source": [
    "### WordNet Organization for Verbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe70f6e-d0ad-4508-a809-cb7516ea1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deny\n",
      "\n",
      "All synsets for run:\n",
      "Synset('run.n.01') - a score in baseball made by a runner touching all four bases safely\n",
      "Synset('test.n.05') - the act of testing something\n",
      "Synset('footrace.n.01') - a race run on foot\n",
      "Synset('streak.n.01') - an unbroken series of events\n",
      "Synset('run.n.05') - (American football) a play in which a player attempts to carry the ball through or past the opposing team\n",
      "Synset('run.n.06') - a regular trip\n",
      "Synset('run.n.07') - the act of running; traveling on foot at a fast pace\n",
      "Synset('run.n.08') - the continuous period of time during which something (a machine or a factory) operates or continues in operation\n",
      "Synset('run.n.09') - unrestricted freedom to use\n",
      "Synset('run.n.10') - the production achieved during a continuous period of operation (of a machine or factory etc.)\n",
      "Synset('rivulet.n.01') - a small stream\n",
      "Synset('political_campaign.n.01') - a race between candidates for elective office\n",
      "Synset('run.n.13') - a row of unravelled stitches\n",
      "Synset('discharge.n.06') - the pouring forth of a fluid\n",
      "Synset('run.n.15') - an unbroken chronological sequence\n",
      "Synset('run.n.16') - a short trip\n",
      "Synset('run.v.01') - move fast by using one's feet, with one foot off the ground at any given time\n",
      "Synset('scat.v.01') - flee; take to one's heels; cut and run\n",
      "Synset('run.v.03') - stretch out over a distance, space, time, or scope; run or extend between two points or beyond a certain point\n",
      "Synset('operate.v.01') - direct or control; projects, businesses, etc.\n",
      "Synset('run.v.05') - have a particular form\n",
      "Synset('run.v.06') - move along, of liquids\n",
      "Synset('function.v.01') - perform as expected when applied\n",
      "Synset('range.v.01') - change or be different within limits\n",
      "Synset('campaign.v.01') - run, stand, or compete for an office or a position\n",
      "Synset('play.v.18') - cause to emit recorded audio or video\n",
      "Synset('run.v.11') - move about freely and without restraint, or act as if running around in an uncontrolled way\n",
      "Synset('tend.v.01') - have a tendency or disposition to do or be something; be inclined\n",
      "Synset('run.v.13') - be operating, running or functioning\n",
      "Synset('run.v.14') - change from one state to another\n",
      "Synset('run.v.15') - cause to perform\n",
      "Synset('run.v.16') - be affected by; be subjected to\n",
      "Synset('prevail.v.03') - continue to exist\n",
      "Synset('run.v.18') - occur persistently\n",
      "Synset('run.v.19') - carry out a process or program, as on a computer or a machine\n",
      "Synset('carry.v.15') - include as the content; broadcast or publicize\n",
      "Synset('run.v.21') - carry out\n",
      "Synset('guide.v.05') - pass over, across, or through\n",
      "Synset('run.v.23') - cause something to pass or lead somewhere\n",
      "Synset('run.v.24') - make without a miss\n",
      "Synset('run.v.25') - deal in illegally, such as arms or liquor\n",
      "Synset('run.v.26') - cause an animal to move fast\n",
      "Synset('run.v.27') - be diffused\n",
      "Synset('run.v.28') - sail before the wind\n",
      "Synset('run.v.29') - cover by running; run a certain distance\n",
      "Synset('run.v.30') - extend or continue for a certain period of time\n",
      "Synset('run.v.31') - set animals loose to graze\n",
      "Synset('run.v.32') - keep company\n",
      "Synset('run.v.33') - run with the ball; in such sports as football\n",
      "Synset('run.v.34') - travel rapidly, by any (unspecified) means\n",
      "Synset('ply.v.03') - travel a route regularly\n",
      "Synset('hunt.v.01') - pursue for food or sport (as of wild animals)\n",
      "Synset('race.v.02') - compete in a race\n",
      "Synset('move.v.13') - progress by being changed\n",
      "Synset('melt.v.01') - reduce or cause to be reduced from a solid to a liquid state, usually by heating\n",
      "Synset('ladder.v.01') - come unraveled or undone as if by snagging\n",
      "Synset('run.v.41') - become undone\n",
      "\n",
      "All synsets for sprint:\n",
      "Synset('dash.n.02') - a quick run\n",
      "Synset('sprint.v.01') - run very fast, usually for a short distance\n",
      "\n",
      "Wu-Palmer similarity metric between Synset('run.n.07') and Synset('sprint.v.01'): 0.125\n",
      "\n",
      "Lesk Algorithm for Synset('run.n.07') on '['He', 'broke', 'into', 'a', 'run']': Synset('run.v.29')\n",
      "\n",
      "Lesk Algorithm for Synset('sprint.v.01') on '['Joe', 'sprinted', 'across', 'the', 'finish', 'line']': Synset('sprint.v.01')\n"
     ]
    }
   ],
   "source": [
    "# Use morphy to find different forms of the word\n",
    "print(wn.morphy(verb, wn.VERB))\n",
    "\n",
    "# Select two words that might be similar\n",
    "word1 = 'run'\n",
    "word2 = 'sprint'\n",
    "\n",
    "# Find the specific synsets you are interested in\n",
    "run = wn.synsets(word1)\n",
    "sprint = wn.synsets(word2)\n",
    "\n",
    "# Output word1 definitions\n",
    "print(f\"\\nAll synsets for {word1}:\")\n",
    "for synset in run:\n",
    "    print(f'{synset} - {synset.definition()}')\n",
    "\n",
    "# Output word2 definitions\n",
    "print(f\"\\nAll synsets for {word2}:\")\n",
    "for synset in sprint:\n",
    "    print(f'{synset} - {synset.definition()}')\n",
    "\n",
    "chosen_word_1 = run[6]\n",
    "chosen_word_2 = sprint[1]\n",
    "\n",
    "# Wu-Palmer similarity metric\n",
    "print(f'\\nWu-Palmer similarity metric between {chosen_word_1} and {chosen_word_2}: {wn.wup_similarity(chosen_word_1, chosen_word_2)}')\n",
    "\n",
    "# Lesk algorithm for word 1 \n",
    "sentence1 = 'He broke into a run'\n",
    "sentence1 = sentence1.split(' ')\n",
    "lesk1 = lesk(sentence1, word1, 'v')\n",
    "print(f'\\nLesk Algorithm for {chosen_word_1} on \\'{sentence1}\\': {lesk1}')\n",
    "\n",
    "# Lesk algorithm for word 2\n",
    "sentence2 = 'Joe sprinted across the finish line'\n",
    "sentence2 = sentence2.split(' ')\n",
    "lesk2 = lesk(sentence2, word2, 'v')\n",
    "print(f'\\nLesk Algorithm for {chosen_word_2} on \\'{sentence2}\\': {lesk2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc5531-1355-4fce-a1d7-b6ca21804699",
   "metadata": {},
   "source": [
    "### Observations about the Wu-Palmer similarity metric and the Lesk algorithm\n",
    "\n",
    "Both the Wu-Palmer similarity metric and the Lesk algorithm are ways oof determining the similarity between two words. The Wu-Palmer similarity metric is a better way of measuring the similarity between two words, and does so by calculating their distance from the closest common hypernym. The Lesk algorithm, on the other hand, determines the most common senses of a word in a context. They are not suitable for 1 to 1 comparisions, and should be applied differently depending on the needs of the program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6448c-0cb0-46de-960c-02747ecb49de",
   "metadata": {},
   "source": [
    "### About SentiWordNet\n",
    "SentiWordNet is a tool used in natural language processing to conduct sentiment analysis on a text. This tool can analyze a text to see if it is positive or negative and how objective it is, and does so by breaking a text down to the words it is made up of and looking up the corresponding synsets. Each synset has a sentiment score, and SentiWordNet combines all the synset scores to get the overall sentiment score. \n",
    "\n",
    "Some use cases for SentiWordNet can be in figuring out how well-liked a product or movie is by looking at reviews. A score can then be assigned as to how generally liked the product is, and this can be compared to other products to see which is the better one. Other use cases may be for ad targeting, where based on a customer's thoughts on different topics ads can be targeted towards them, or for guessing how a stock price will do based on seniment towards that company on social media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d351351-e0dc-4622-b1c6-00a069f0df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: desperate.n.01\n",
      "Positive Score: 0.0\n",
      "Negative Score: 0.25\n",
      "Objective Score: 0.75\n",
      "\n",
      "Name: despairing.s.01\n",
      "Positive Score: 0.0\n",
      "Negative Score: 0.5\n",
      "Objective Score: 0.5\n",
      "\n",
      "Name: desperate.s.02\n",
      "Positive Score: 0.125\n",
      "Negative Score: 0.25\n",
      "Objective Score: 0.625\n",
      "\n",
      "Name: desperate.s.03\n",
      "Positive Score: 0.125\n",
      "Negative Score: 0.625\n",
      "Objective Score: 0.25\n",
      "\n",
      "Name: desperate.s.04\n",
      "Positive Score: 0.5\n",
      "Negative Score: 0.125\n",
      "Objective Score: 0.375\n",
      "\n",
      "Name: desperate.s.05\n",
      "Positive Score: 0.5\n",
      "Negative Score: 0.125\n",
      "Objective Score: 0.375\n",
      "\n",
      "Name: desperate.s.06\n",
      "Positive Score: 0.0\n",
      "Negative Score: 0.5\n",
      "Objective Score: 0.5\n",
      "\n",
      "\n",
      "Polarity for each word in the sentence:\n",
      "Word: Bob\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: was\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: desperate\n",
      "Polarity: -0.25\n",
      "\n",
      "Word: after\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: he\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: lost\n",
      "Polarity: 0.0\n",
      "\n",
      "'his' has no synset\n",
      "\n",
      "Word: job\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: due\n",
      "Polarity: 0.375\n",
      "\n",
      "'to' has no synset\n",
      "\n",
      "'the' has no synset\n",
      "\n",
      "Word: mass\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: layoffs\n",
      "Polarity: 0.0\n",
      "\n",
      "Word: in\n",
      "Polarity: 0.0\n",
      "\n",
      "'the' has no synset\n",
      "\n",
      "Word: tech\n",
      "Polarity: 0.0\n",
      "\n",
      "'industry.' has no synset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/hasani/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Select an emotionally charged word\n",
    "charged_word = 'desperate'\n",
    "\n",
    "# Find its senti-synsets\n",
    "synsets = swn.senti_synsets(charged_word)\n",
    "\n",
    "# Output the polarity scores for each word\n",
    "for synset in synsets:\n",
    "    print(f'\\nName: {synset.synset.name()}')\n",
    "    print(f'Positive Score: {synset.pos_score()}')\n",
    "    print(f'Negative Score: {synset.neg_score()}')\n",
    "    print(f'Objective Score: {synset.obj_score()}')\n",
    "    \n",
    "# Make up a sentence\n",
    "sentence = 'Bob was desperate after he lost his job due to the mass layoffs in the tech industry.'\n",
    "sentence = sentence.split(' ')\n",
    "\n",
    "# Output the polarity for each word in the sentence\n",
    "print('\\n\\nPolarity for each word in the sentence:')\n",
    "for word in sentence:\n",
    "    try:\n",
    "        synset = list(swn.senti_synsets(word))[0]\n",
    "        print(f'Word: {word}')\n",
    "        print(f'Polarity: {synset.pos_score() - synset.neg_score()}\\n')\n",
    "    except:\n",
    "        print(f'\\'{word}\\' has no synset\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec1deb-5878-45f8-aec3-15d1423a7c9f",
   "metadata": {},
   "source": [
    "### Observations of the Scores and the Utility of Knowing these Scores in an NLP Application\n",
    "\n",
    "From looking at the scores outputted, one observation that can be made is that the context in which a word is used can change the sentiment value of the word, and that different uses of the word can have different polarities. In an NLP application, knowing these scores can be useful because one can use the sentiment of the word for tasks such as sentiment analysis on a text, among other projects. See the section 'About SentiWordNet' for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6e0f0-53ae-4e3f-b377-27ba35f6e58b",
   "metadata": {},
   "source": [
    "### Collocations \n",
    "\n",
    "A collocation is when two or more words occur together in a language as a saying, and where substituting one word for any synonym of the word would result in a sentence that does not make sense. Collocations can be used in the context of NLP to help identify patterns in usage for various words and phrases.\n",
    "\n",
    "For example, a \"strong coffee\" is not the same thing as a \"muscular coffee\", and the phrase \"muscular coffee\" does not make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a34df305-69c1-4d41-91b3-115d0ecc8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /Users/hasani/nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "None\n",
      "\n",
      "Selected Collocation: ('fellow', 'citizens')\n",
      "Number of tokens: 152019\n",
      "P(fellow citizens) = 0.0004012656312697755\n",
      "P(fellow) = 0.000901203139081299\n",
      "P(citizens) = 0.0017760937777514653\n",
      "PMI = 7.969781781267196\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "nltk.download('inaugural')\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.text import Text\n",
    "\n",
    "\n",
    "# Load text4 with inaugural corpus\n",
    "text4 = Text(inaugural.words())\n",
    "\n",
    "# Output collocations for text4\n",
    "print(text4.collocations())\n",
    "\n",
    "# Select one of the collocations identified by NLTK\n",
    "selected_collocation = list(text4.collocation_list())[1]\n",
    "print(f'\\nSelected Collocation: {selected_collocation}')\n",
    "\n",
    "\n",
    "# Calculate mutual information using equation: LOG2(P(x,y)/[P(x)*P(y)])\n",
    "\n",
    "# Load up raw text4 data and tokenize\n",
    "text4 = inaugural.raw() \n",
    "tokens = nltk.word_tokenize(text4)\n",
    "\n",
    "# Calculate number of tokens\n",
    "text_len = len(tokens)\n",
    "print(f'Number of tokens: {text_len}')\n",
    "\n",
    "# Stringify selected collocation\n",
    "word = ' '.join(selected_collocation)\n",
    "\n",
    "# Number of times selected collocation occurs divided by text len\n",
    "sc = text.count(word)/text_len\n",
    "print(f'P({word}) = {sc}')\n",
    "\n",
    "# Number of times first word in selected collocation occurs divided by text len\n",
    "first_word = text.count(selected_collocation[0])/text_len\n",
    "print(f'P({selected_collocation[0]}) = {first_word}')\n",
    "\n",
    "# Number of times second word in selected collocation occurs divided by text len\n",
    "second_word = text.count(selected_collocation[1])/text_len\n",
    "print(f'P({selected_collocation[1]}) = {second_word}')\n",
    "\n",
    "# PMI score logic: log2(P(both words)/[P(first word)*P(second word)])\n",
    "pmi = math.log2(sc / (first_word * second_word))\n",
    "print(f'PMI = {pmi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4db1b-4e05-4177-800d-bdd977559058",
   "metadata": {},
   "source": [
    "### Commentary on the Results of the Mutual Information Formula\n",
    "\n",
    "The mutual information formula were found using point-wise mutual information. The results of the formula show that the because the PMI score is a positive number, then the selected phrase is likely to be a collocation. We can also input a generic phrase and calculate the mutual information score of the phrase, and will see that the phrase has a significantly lower, if not negative, PMI score, leading to the conclusion that the selected phrase is a collocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fa451-c6fc-43c8-ae02-4f1a2f66dcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
